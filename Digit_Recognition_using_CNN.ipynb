{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognition using CNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r9A-82QTE9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5e225150-2a63-4ea4-8f2c-bd56f49f87e9"
      },
      "source": [
        "from keras.datasets import mnist#download mnist data and split into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQIHQbXWiU5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9-KDcpoTPhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9a015e2b-54b3-46ba-cca5-b35106433728"
      },
      "source": [
        "#plot a few images to explore the samples\n",
        "\n",
        "import matplotlib.pyplot as plt#plot the first image in the dataset\n",
        "plt.imshow(X_train[7])\n",
        "print(y_train[7])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAONElEQVR4nO3dbYxc5XnG8evCrE0xOLVN4rrEBAg0QKhq6MokQFsKaXCQKgNKeVGTmgZhRCAkkqsU0Q9BaivRiIRGUYNqiolJKQlScG01VoLrJkGhxMIgB9sYsAOmeFlsqNViQmyvvXc/7CFdYOfZZd7OLPf/J61m9txzzrl1vJfPzDwz53FECMC732F1NwCgOwg7kARhB5Ig7EAShB1I4vBu7myqp8URmt7NXQKp7NMvdCD2e6xaS2G3vVDS1yRNkfRPEXFr6fFHaLrO8gWt7BJAwfpY17DW9NN421Mk/YOkT0g6TdKVtk9rdnsAOquV1+wLJG2PiGcj4oCkb0ta1J62ALRbK2E/VtILo37fWS17E9tLbG+wvWFI+1vYHYBWdPzd+IhYFhH9EdHfp2md3h2ABloJ+4CkeaN+f3+1DEAPaiXsj0o62fYJtqdKukLS6va0BaDdmh56i4iDtm+Q9AONDL0tj4gtbesMQFu1NM4eEWskrWlTLwA6iI/LAkkQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kERLs7iiN/h3P9ywNjy1/E88cN70Yn3L575RrA/FoWK9Thds/mTD2vRFg8V1h/fta3c7tWsp7LZ3SNor6ZCkgxHR346mALRfO87sfxgRr7RhOwA6iNfsQBKthj0kPWj7MdtLxnqA7SW2N9jeMKT9Le4OQLNafRp/bkQM2H6fpLW2n4qIh0Y/ICKWSVomSTM8K1rcH4AmtXRmj4iB6na3pJWSFrSjKQDt13TYbU+3ffQb9yV9XNLmdjUGoL1aeRo/R9JK229s518i4vtt6SqZ+OjvFOvbrpparN9+/n0Na30+WFz3Y7+2t1gfivL5YFjDxXqd1p5+f8Pa/G99prjuCde9WKwfeuW/m+qpTk2HPSKelVT+KwXQMxh6A5Ig7EAShB1IgrADSRB2IAm+4toD4m/2FOtPnfJAlzrJY+PZy4v1C8/6bLE+7XuTb+iNMzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4ew8Y+NG88gNOaX7bj+ybVqx/Zs015Q14nB20cO2hj5z5TLF+9/EPNr9xvA1ndiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhHdm6RlhmfFWb6ga/ubLNxXvlT0YSce1/y2DwwV6wefe77pbbdqyjGzi/Xrf/pwsT7eZbBLzt90ebE+49KXivXh119vet+dtD7W6dXYM+anIzizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASfJ+9B8TQgWL90NPbu9RJd+269LeK9d+eumqcLZS/q1/y4ouzivWjXn+26W33qnHP7LaX295te/OoZbNsr7W9rbqd2dk2AbRqIk/jvylp4VuW3SRpXUScLGld9TuAHjZu2CPiIUlvnZ9okaQV1f0Vki5uc18A2qzZ1+xzImKwuv+SpDmNHmh7iaQlknSEjmxydwBa1fK78THyTZqG36aJiGUR0R8R/X0tvKECoDXNhn2X7bmSVN3ubl9LADqh2bCvlrS4ur9Y0nhjJABqNu5rdtv3STpP0jG2d0r6kqRbJd1v+2pJz0u6rJNNYvJ6+bqPNqyd8qmniuvOmdK5l32nfvG5Yv1Qx/Zcn3HDHhFXNihxFQpgEuHjskAShB1IgrADSRB2IAnCDiTBV1xRtPuGs4v1xdetKdY/NeO2hrWjDytfQrtVf/3ymQ1rsb/8teJ3I87sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+w9YMqHP1SsP/Pn5Yv3/sG5m4v1VvzbvK8X68MaHmcLzY+lbx86WKxffsfSYv24lbsa1ob3/rypniYzzuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7F0Q58wv1q+6e2Wxvmj6K+1s5x2q73xw4/bLi/Vj/+4/i/V34+WgW8GZHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9B0xRFOuH1fh/cp+nFOtD5dZb8v1Ty58/+L0/vb5Yf8+9P21nO5PeuH9Ftpfb3m1786hlt9gesL2x+rmos20CaNVEThnflLRwjOW3R8T86qc8LQiA2o0b9oh4SNKeLvQCoINaeTF4g+0nqqf5DS+SZnuJ7Q22Nwxpfwu7A9CKZsN+h6QPSpovaVDSVxo9MCKWRUR/RPT3aVqTuwPQqqbCHhG7IuJQRAxLulPSgva2BaDdmgq77bmjfr1EUueuZQygLcYdZ7d9n6TzJB1je6ekL0k6z/Z8SSFph6RrO9jjpOeHNxbrd1081mDH/7vpqtnF+nE/aDzX+JRflq+93mnbru5rWHtq4R1d7ATjhj0irhxj8V0d6AVAB/FxWSAJwg4kQdiBJAg7kARhB5LgK6494NCTzxTrJ36xS410wKnb3tu4WB5xRJtxZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnR0ftuvSkultAhTM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsEeVrj2Wz+50/OKK47c9WWYn14796meuoFg0vPLtZX3fjlQpUZgrqJMzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4e2XfHy8o1t/zF//VsPbjk75eXPeSR8eaCHeUp+sbZz987m8U6wOfPLFY/87nbivWf/Pw5sfSdx3aX6z3/TKa3nZG457Zbc+z/UPbT9reYvvz1fJZttfa3lbdzux8uwCaNZGn8QclLY2I0yR9RNL1tk+TdJOkdRFxsqR11e8AetS4YY+IwYh4vLq/V9JWScdKWiRpRfWwFZIu7lSTAFr3jl6z2z5e0hmS1kuaExGDVeklSXMarLNE0hJJOkJHNtsngBZN+N1420dJ+q6kL0TEq6NrERGSxny3JCKWRUR/RPT38cUHoDYTCrvtPo0E/d6IeKBavMv23Ko+V9LuzrQIoB3GfRpv25LukrQ1Ir46qrRa0mJJt1a3qzrSYZdc+Lc/LtaXzt7c9LafunlG+QGvndX0tlt1xdmPFOv/+r7vFevD6mt634t3XFisb7/7Q8X67AfKvePNJvKa/RxJn5a0yfbGatnNGgn5/bavlvS8pMs60yKAdhg37BHxE0luUL6gve0A6BQ+LgskQdiBJAg7kARhB5Ig7EASfMW1C7Z+7B/rbqEF5fPBI/vKn4q8Zv2fNayddM224rqzf8E4ejtxZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnr/zHjecU6/d8tvGlpn92zvJ2t9M2//zqvGJ9cOjXi/Xlj5ePy0l3HirWT3x4Y8PacHFNtBtndiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwiOTuXTHDM+Kszw5L0h72JGNp6564cb5xXVXXPv3xfrpUxtdvHfE+ZsuL9b/90eNp13+wHcGiusefO75Yh2Ty/pYp1djz5h/UJzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJccfZbc+TdI+kOZJC0rKI+JrtWyRdI+nl6qE3R8Sa0rYm8zg7MBmUxtkncvGKg5KWRsTjto+W9JjttVXt9oi4rV2NAuiciczPPihpsLq/1/ZWScd2ujEA7fWOXrPbPl7SGZLWV4tusP2E7eW2ZzZYZ4ntDbY3DGl/S80CaN6Ew277KEnflfSFiHhV0h2SPihpvkbO/F8Za72IWBYR/RHR36fyvGAAOmdCYbfdp5Gg3xsRD0hSROyKiEMRMSzpTkmNr8gIoHbjht22Jd0laWtEfHXU8rmjHnaJpM3tbw9Au0zk3fhzJH1a0ibbb1wX+GZJV9qer5HhuB2Sru1IhwDaYiLvxv9E0ljjdsUxdQC9hU/QAUkQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkujqlM22X5Y0eo7gYyS90rUG3ple7a1X+5LorVnt7O0DEfHesQpdDfvbdm5viIj+2hoo6NXeerUvid6a1a3eeBoPJEHYgSTqDvuymvdf0qu99WpfEr01qyu91fqaHUD31H1mB9AlhB1Iopaw215o+2nb223fVEcPjdjeYXuT7Y22N9Tcy3Lbu21vHrVslu21trdVt2POsVdTb7fYHqiO3UbbF9XU2zzbP7T9pO0ttj9fLa/12BX66spx6/prdttTJD0j6Y8k7ZT0qKQrI+LJrjbSgO0dkvojovYPYNj+fUmvSbonIk6vln1Z0p6IuLX6j3JmRPxlj/R2i6TX6p7Gu5qtaO7oacYlXSzpKtV47Ap9XaYuHLc6zuwLJG2PiGcj4oCkb0taVEMfPS8iHpK05y2LF0laUd1foZE/lq5r0FtPiIjBiHi8ur9X0hvTjNd67Ap9dUUdYT9W0gujft+p3prvPSQ9aPsx20vqbmYMcyJisLr/kqQ5dTYzhnGn8e6mt0wz3jPHrpnpz1vFG3Rvd25EnCnpE5Kur56u9qQYeQ3WS2OnE5rGu1vGmGb8V+o8ds1Of96qOsI+IGneqN/fXy3rCRExUN3ulrRSvTcV9a43ZtCtbnfX3M+v9NI03mNNM64eOHZ1Tn9eR9gflXSy7RNsT5V0haTVNfTxNranV2+cyPZ0SR9X701FvVrS4ur+YkmrauzlTXplGu9G04yr5mNX+/TnEdH1H0kXaeQd+Z9L+qs6emjQ14mSflb9bKm7N0n3aeRp3ZBG3tu4WtJsSeskbZP075Jm9VBv35K0SdITGgnW3Jp6O1cjT9GfkLSx+rmo7mNX6Ksrx42PywJJ8AYdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTxf2YjLzDBs2ChAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSkHr0FoTdH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2e6b87e-4eb3-4a01-f6d3-c34f861a7ba1"
      },
      "source": [
        "#the shape is again 28px*28px\n",
        "\n",
        "X_train[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clvxAITtUsc5",
        "colab_type": "text"
      },
      "source": [
        "Data pre-processing\n",
        "\n",
        "Next, we need to reshape our dataset inputs (X_train and X_test) to the shape that our model expects when we train the model. The first number is the number of images (60,000 for X_train and 10,000 for X_test). Then comes the shape of each image (28x28). The last number is 1, which signifies that the images are greyscale.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ28huCBUwA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4570450-a63f-413a-970c-c0f6e356a3dd"
      },
      "source": [
        "#reshape data to fit model\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br8qe7MWVGNH",
        "colab_type": "text"
      },
      "source": [
        "We will one-hot encode our target variable in training and testing set(labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1QE85XfVPgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3554410b-17f4-4357-abba-47029387f5b6"
      },
      "source": [
        "from keras.utils import to_categorical#one-hot encode target column\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu_d1xoAVgRd",
        "colab_type": "text"
      },
      "source": [
        "Our first 2 layers are Conv2D layers. These are convolution layers that will deal with our input images, which are seen as 2-dimensional matrices.\n",
        "\n",
        "64 in the first layer and 32 in the second layer are the number of nodes in each layer. This number can be adjusted to be higher or lower, depending on the size of the dataset. In our case, 64 and 32 work well, so we will stick with this for now.\n",
        "\n",
        "Kernel size is the size of the filter matrix for our convolution. So a kernel size of 3 means we will have a 3x3 filter matrix. Refer back to the introduction and the first image for a refresher on this.\n",
        "\n",
        "Activation is the activation function for the layer. The activation function we will be using for our first 2 layers is the ReLU, or Rectified Linear Activation. This activation function has been proven to work well in neural networks.\n",
        "\n",
        "\n",
        "Our first layer also takes in an input shape. This is the shape of each input image, 28,28,1 as seen earlier on, with the 1 signifying that the images are greyscale.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE_zCgTPVey1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten#create model\n",
        "model = Sequential()#add model layers\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_yMz5uUgL52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1kSs4cketGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "eddf67bc-6972-4dd0-bd3d-9d3095d75ae1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        18464     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                184330    \n",
            "=================================================================\n",
            "Total params: 203,434\n",
            "Trainable params: 203,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vidIOAbHiIPm",
        "colab_type": "text"
      },
      "source": [
        "Training the model\n",
        "\n",
        "Now we will train our model. To train, we will use the ‘fit()’ function on our model with the following parameters: training data (train_X), target data (train_y), validation data, and the number of epochs.\n",
        "\n",
        "For our validation data, we will use the test set provided to us in our dataset, which we have split into X_test and y_test.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XSUHhDCgbtJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "e9ec2dfe-d1b6-48ff-aaa7-dff84d878353"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "1875/1875 [==============================] - 164s 87ms/step - loss: 0.2121 - accuracy: 0.9528 - val_loss: 0.0724 - val_accuracy: 0.9764\n",
            "Epoch 2/8\n",
            "1875/1875 [==============================] - 164s 87ms/step - loss: 0.0671 - accuracy: 0.9802 - val_loss: 0.0828 - val_accuracy: 0.9775\n",
            "Epoch 3/8\n",
            "1875/1875 [==============================] - 164s 87ms/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.0759 - val_accuracy: 0.9797\n",
            "Epoch 4/8\n",
            "1875/1875 [==============================] - 164s 87ms/step - loss: 0.0368 - accuracy: 0.9886 - val_loss: 0.1124 - val_accuracy: 0.9754\n",
            "Epoch 5/8\n",
            "1875/1875 [==============================] - 164s 87ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0983 - val_accuracy: 0.9772\n",
            "Epoch 6/8\n",
            "1875/1875 [==============================] - 164s 87ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.1092 - val_accuracy: 0.9798\n",
            "Epoch 7/8\n",
            "1875/1875 [==============================] - 164s 88ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.1296 - val_accuracy: 0.9790\n",
            "Epoch 8/8\n",
            "1875/1875 [==============================] - 165s 88ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.1323 - val_accuracy: 0.9780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f693099c5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10nV0hKqiCUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "aa2637bd-0e38-4d70-fa97-aff9f75aaaa5"
      },
      "source": [
        "#predict first 4 images in the test set\n",
        "model.predict(X_test[:4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.9584625e-19, 1.0544627e-24, 1.4317620e-15, 4.1769040e-13,\n",
              "        4.6396871e-19, 2.2483785e-19, 9.1760504e-26, 1.0000000e+00,\n",
              "        2.0486545e-13, 7.6189340e-14],\n",
              "       [1.0478367e-12, 1.4086032e-14, 1.0000000e+00, 6.4747622e-16,\n",
              "        6.8597080e-19, 1.3769485e-23, 1.0893702e-08, 1.2096095e-20,\n",
              "        1.9204432e-14, 1.1586957e-19],\n",
              "       [9.1086329e-13, 9.9992049e-01, 6.5791608e-09, 1.2956405e-19,\n",
              "        8.3635916e-07, 2.3643563e-13, 6.8803475e-16, 1.0705247e-10,\n",
              "        7.8653466e-05, 1.0127123e-13],\n",
              "       [1.0000000e+00, 4.0131014e-23, 2.0831348e-18, 3.5376598e-16,\n",
              "        9.8468608e-20, 3.3104152e-14, 7.5232189e-11, 2.4894616e-17,\n",
              "        1.1245980e-12, 2.1961581e-10]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4snzFX4iQLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "070d320c-8383-4135-d4ed-f7e3590b06bf"
      },
      "source": [
        "for val in model.predict(X_test[:4]):\n",
        "  print(np.argmax(val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "2\n",
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP8Y0ApFilJw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "cdcd6991-04f4-429e-a1d8-d19c3b0ebe7e"
      },
      "source": [
        "#see the actual result to verify\n",
        "y_test[::4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mtRTprHlznn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4cd8084f-dcb8-44f6-a328-8ead4c10a8ee"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 6s 20ms/step - loss: 0.1323 - accuracy: 0.9780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13227495551109314, 0.9779999852180481]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X08v5xmldsPy",
        "colab_type": "text"
      },
      "source": [
        "The accuracy is close to 98 percent\n"
      ]
    }
  ]
}